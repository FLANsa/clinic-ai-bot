"""
CSV Import Router - Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª CSV
"""
import logging
import csv
import io
from typing import List, Dict, Any
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File
from sqlalchemy.orm import Session
from sqlalchemy import inspect as sqlalchemy_inspect
from sqlalchemy import create_engine
from datetime import datetime
import uuid
from app.db.session import get_db
from app.middleware.auth import verify_api_key
from app.config import get_settings
from app.db.models import Branch, Doctor, Service

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/admin/csv-import", tags=["Admin - CSV Import"])

settings = get_settings()


def parse_working_hours(work_hours_str: str) -> Dict[str, Any]:
    """
    ØªØ­Ù„ÙŠÙ„ Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø¹Ù…Ù„ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø¥Ù„Ù‰ JSON
    Ù…Ø«Ø§Ù„: "Ù…Ù† 8Øµ Ø­ØªÙ‰ 1Øµ ÙˆØ§Ù„Ø¬Ù…Ø¹Ø© Ù…Ù† 1Ù…-1Øµ"
    """
    if not work_hours_str or work_hours_str.strip() == "":
        return {
            "sunday": {"from": "08:00", "to": "01:00"},
            "monday": {"from": "08:00", "to": "01:00"},
            "tuesday": {"from": "08:00", "to": "01:00"},
            "wednesday": {"from": "08:00", "to": "01:00"},
            "thursday": {"from": "08:00", "to": "01:00"},
            "friday": {"from": "13:00", "to": "01:00"},
            "saturday": {"from": "08:00", "to": "01:00"}
        }
    
    # ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· - ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹
    work_hours_str = work_hours_str.strip()
    
    # Ø§ÙØªØ±Ø§Ø¶ÙŠ: Ù…Ù† 8 ØµØ¨Ø§Ø­Ø§Ù‹ Ø­ØªÙ‰ 1 ØµØ¨Ø§Ø­Ø§Ù‹
    default_hours = {
        "sunday": {"from": "08:00", "to": "01:00"},
        "monday": {"from": "08:00", "to": "01:00"},
        "tuesday": {"from": "08:00", "to": "01:00"},
        "wednesday": {"from": "08:00", "to": "01:00"},
        "thursday": {"from": "08:00", "to": "01:00"},
        "friday": {"from": "13:00", "to": "01:00"},  # Ø§Ù„Ø¬Ù…Ø¹Ø© Ù…Ù† 1 Ø¸Ù‡Ø±Ø§Ù‹
        "saturday": {"from": "08:00", "to": "01:00"}
    }
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ "Ø§Ù„Ø¬Ù…Ø¹Ø©"
    if "Ø§Ù„Ø¬Ù…Ø¹Ø©" in work_hours_str:
        if "1Ù…" in work_hours_str or "1 Ø¸Ù‡Ø±Ø§Ù‹" in work_hours_str:
            default_hours["friday"] = {"from": "13:00", "to": "01:00"}
    
    return default_hours


@router.post("/import-local-csv")
async def import_local_csv(
    db: Session = Depends(get_db),
    api_key: str = Depends(verify_api_key)
):
    """
    Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª CSV Ø§Ù„Ù…Ø­Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
    ÙŠÙ‚Ø±Ø£ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ù†: branches_import.csv, doctors_import.csv, services_import.csv
    """
    logger.info("Ø¨Ø¯Ø¡ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª CSV Ø§Ù„Ù…Ø­Ù„ÙŠØ©...")
    
    try:
        from pathlib import Path
        import os
        
        # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
        project_root = Path(__file__).parent.parent.parent.parent.parent
        csv_dir = project_root / "clinic-ai-bot"
        
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø¬Ø±Ø¨ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ
        if not csv_dir.exists():
            csv_dir = project_root
        
        details = {}
        counts = {"branches": 0, "doctors": 0, "services": 0}
        now = datetime.now()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        engine = create_engine(settings.DATABASE_URL, isolation_level="AUTOCOMMIT")
        inspector = sqlalchemy_inspect(engine)
        existing_tables = inspector.get_table_names()
        
        required_tables = ["branches", "doctors", "services"]
        missing_tables = [table for table in required_tables if table not in existing_tables]
        
        if missing_tables:
            raise HTTPException(
                status_code=400,
                detail=f"Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {', '.join(missing_tables)}. ÙŠØ±Ø¬Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹."
            )
        
        # 1. Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ÙØ±ÙˆØ¹
        branches_file_path = csv_dir / "branches_import.csv"
        if branches_file_path.exists():
            logger.info(f"ğŸ“‚ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„ÙØ±ÙˆØ¹: {branches_file_path}")
            with open(branches_file_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                branches_added = 0
                for row in reader:
                    branch_name = row.get('name_ar', '').strip()
                    if not branch_name:
                        continue
                    
                    existing = db.query(Branch).filter(Branch.name == branch_name).first()
                    if not existing:
                        branch = Branch(
                            id=uuid.uuid4(),
                            name=branch_name,
                            city=row.get('district_ar', '').strip() or "Ø§Ù„Ø±ÙŠØ§Ø¶",
                            address=row.get('address_ar', '').strip() or row.get('district_ar', '').strip(),
                            phone=row.get('phone', '').strip(),
                            location_url=row.get('map_url', '').strip(),
                            working_hours=parse_working_hours(row.get('work_hours_ar', '')),
                            is_active=True,
                            created_at=now,
                            updated_at=now
                        )
                        db.add(branch)
                        branches_added += 1
                
                db.commit()
                counts["branches"] = branches_added
                logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {branches_added} ÙØ±Ø¹")
        else:
            logger.warning(f"âš ï¸  Ù…Ù„Ù branches_import.csv ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ: {branches_file_path}")
        
        # 2. Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡
        doctors_file_path = csv_dir / "doctors_import.csv"
        if doctors_file_path.exists():
            logger.info(f"ğŸ“‚ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡: {doctors_file_path}")
            with open(doctors_file_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                doctors_added = 0
                for row in reader:
                    doctor_name = row.get('doctor_name_ar', '').strip()
                    if not doctor_name:
                        continue
                    
                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙØ±Ø¹
                    branch_code = row.get('branch_code', '').strip()
                    branch_id = None
                    if branch_code:
                        # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ÙƒÙˆØ¯ Ø£ÙˆÙ„Ø§Ù‹
                        branch = db.query(Branch).filter(Branch.name.like(f'%{branch_code}%')).first()
                        if not branch:
                            # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø§Ø³Ù…
                            if branch_code == 'north_hazm':
                                branch = db.query(Branch).filter(Branch.name.like('%Ø´Ù…Ø§Ù„%')).first()
                        if branch:
                            branch_id = branch.id
                    
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø·Ø¨ÙŠØ¨
                    existing = db.query(Doctor).filter(
                        Doctor.name == doctor_name,
                        Doctor.branch_id == branch_id
                    ).first()
                    
                    if not existing:
                        # ØªØ­Ù„ÙŠÙ„ Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø®Ø¨Ø±Ø©
                        experience_years = None
                        exp_str = row.get('experience_years', '').strip() or row.get('experience_ar', '').strip()
                        if exp_str:
                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
                            import re
                            numbers = re.findall(r'\d+', exp_str)
                            if numbers:
                                try:
                                    experience_years = int(numbers[0])
                                except:
                                    pass
                        
                        doctor = Doctor(
                            id=uuid.uuid4(),
                            name=doctor_name,
                            specialty=row.get('specialty_ar', '').strip() or row.get('department_ar', '').strip(),
                            license_number=f"LIC-{uuid.uuid4().hex[:8].upper()}",
                            branch_id=branch_id,
                            working_hours=parse_working_hours(row.get('work_hours_ar', '')),
                            experience_years=str(experience_years) if experience_years else None,
                            bio=row.get('cases_ar', '').strip() or row.get('notes_ar', '').strip(),
                            is_active=row.get('status_ar', '').strip() == 'Ø¹Ù„Ù‰ Ø±Ø£Ø³ Ø§Ù„Ø¹Ù…Ù„',
                            created_at=now,
                            updated_at=now
                        )
                        db.add(doctor)
                        doctors_added += 1
                
                db.commit()
                counts["doctors"] = doctors_added
                logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {doctors_added} Ø·Ø¨ÙŠØ¨")
        else:
            logger.warning(f"âš ï¸  Ù…Ù„Ù doctors_import.csv ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ: {doctors_file_path}")
        
        # 3. Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
        services_file_path = csv_dir / "services_import.csv"
        if services_file_path.exists():
            logger.info(f"ğŸ“‚ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø®Ø¯Ù…Ø§Øª: {services_file_path}")
            with open(services_file_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                services_added = 0
                for row in reader:
                    service_name = row.get('name_ar', '').strip()
                    if not service_name:
                        continue
                    
                    existing = db.query(Service).filter(Service.name == service_name).first()
                    if not existing:
                        price_str = row.get('price_sar', '').strip()
                        base_price = None
                        if price_str:
                            try:
                                base_price = float(price_str)
                            except ValueError:
                                pass
                        
                        description = row.get('description_ar', '').strip() or row.get('notes', '').strip()
                        if not description and row.get('category_ar', '').strip():
                            description = f"({row.get('category_ar', '').strip()})"
                        
                        service = Service(
                            id=uuid.uuid4(),
                            name=service_name,
                            description=description,
                            base_price=base_price,
                            is_active=True,
                            created_at=now,
                            updated_at=now
                        )
                        db.add(service)
                        services_added += 1
                
                db.commit()
                counts["services"] = services_added
                logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {services_added} Ø®Ø¯Ù…Ø©")
        else:
            logger.warning(f"âš ï¸  Ù…Ù„Ù services_import.csv ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ: {services_file_path}")
        
        summary = f"""
âœ… ØªÙ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª CSV Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!

ğŸ“Š Ø§Ù„Ù…Ù„Ø®Øµ:
- Ø§Ù„ÙØ±ÙˆØ¹ Ø§Ù„Ù…Ø¶Ø§ÙØ©: {counts.get('branches', 0)}
- Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ Ø§Ù„Ù…Ø¶Ø§ÙÙˆÙ†: {counts.get('doctors', 0)}
- Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø¶Ø§ÙØ©: {counts.get('services', 0)}
        """
        
        return {
            "success": True,
            "message": summary.strip(),
            "details": {"counts": counts}
        }
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        error_msg = str(e)
        logger.error(f"âŒ ÙØ´Ù„ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† CSV Ø§Ù„Ù…Ø­Ù„ÙŠØ©: {error_msg}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {error_msg[:200]}"
        )


@router.post("/import-from-csv")
async def import_from_csv(
    branches_file: UploadFile = File(None),
    doctors_file: UploadFile = File(None),
    services_file: UploadFile = File(None),
    db: Session = Depends(get_db),
    api_key: str = Depends(verify_api_key)
):
    """
    Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª CSV
    
    ÙŠÙ‚Ø¨Ù„ 3 Ù…Ù„ÙØ§Øª:
    - branches_file: Ù…Ù„Ù CSV Ù„Ù„ÙØ±ÙˆØ¹
    - doctors_file: Ù…Ù„Ù CSV Ù„Ù„Ø£Ø·Ø¨Ø§Ø¡
    - services_file: Ù…Ù„Ù CSV Ù„Ù„Ø®Ø¯Ù…Ø§Øª
    """
    logger.info("Ø¨Ø¯Ø¡ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª CSV...")
    
    try:
        from app.db.base import Base
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        engine = create_engine(settings.DATABASE_URL, isolation_level="AUTOCOMMIT")
        inspector = sqlalchemy_inspect(engine)
        existing_tables = inspector.get_table_names()
        
        required_tables = ["branches", "doctors", "services"]
        missing_tables = [table for table in required_tables if table not in existing_tables]
        
        if missing_tables:
            raise HTTPException(
                status_code=400,
                detail=f"Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {', '.join(missing_tables)}. ÙŠØ±Ø¬Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹."
            )
        
        details = {}
        counts = {"branches": 0, "doctors": 0, "services": 0}
        now = datetime.now()
        
        # 1. Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ÙØ±ÙˆØ¹
        if branches_file:
            logger.info("ğŸ“‚ Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„ÙØ±ÙˆØ¹...")
            content = await branches_file.read()
            csv_content = content.decode('utf-8-sig')  # Ø¯Ø¹Ù… BOM
            reader = csv.DictReader(io.StringIO(csv_content))
            
            branches_added = 0
            for row in reader:
                branch_name = row.get('name_ar', '').strip()
                if not branch_name:
                    continue
                
                existing = db.query(Branch).filter(Branch.name == branch_name).first()
                if not existing:
                    branch = Branch(
                        id=uuid.uuid4(),
                        name=branch_name,
                        city=row.get('district_ar', '').strip() or "Ø§Ù„Ø±ÙŠØ§Ø¶",
                        address=row.get('address_ar', '').strip() or row.get('district_ar', '').strip(),
                        phone=row.get('phone', '').strip(),
                        location_url=row.get('map_url', '').strip(),
                        working_hours=parse_working_hours(row.get('work_hours_ar', '')),
                        is_active=True,
                        created_at=now,
                        updated_at=now
                    )
                    db.add(branch)
                    branches_added += 1
            
            db.commit()
            counts["branches"] = branches_added
            logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {branches_added} ÙØ±Ø¹")
        
        # 2. Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡
        if doctors_file:
            logger.info("ğŸ“‚ Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡...")
            content = await doctors_file.read()
            csv_content = content.decode('utf-8-sig')
            reader = csv.DictReader(io.StringIO(csv_content))
            
            doctors_added = 0
            for row in reader:
                doctor_name = row.get('doctor_name_ar', '').strip()
                if not doctor_name:
                    continue
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙØ±Ø¹
                branch_code = row.get('branch_code', '').strip()
                branch_id = None
                if branch_code:
                    branch = db.query(Branch).filter(Branch.name.like(f'%{branch_code}%')).first()
                    if not branch:
                        # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„
                        if branch_code == 'north_hazm':
                            branch = db.query(Branch).filter(Branch.name.like('%Ø´Ù…Ø§Ù„%')).first()
                    if branch:
                        branch_id = branch.id
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø·Ø¨ÙŠØ¨
                existing = db.query(Doctor).filter(
                    Doctor.name == doctor_name,
                    Doctor.branch_id == branch_id
                ).first()
                
                if not existing:
                    doctor = Doctor(
                        id=uuid.uuid4(),
                        name=doctor_name,
                        specialty=row.get('specialty_ar', '').strip() or row.get('department_ar', '').strip(),
                        license_number=f"LIC-{uuid.uuid4().hex[:8].upper()}",
                        branch_id=branch_id,
                        working_hours=parse_working_hours(row.get('work_hours_ar', '')),
                        experience_years=row.get('experience_years', '').strip() or row.get('experience_ar', '').strip(),
                        is_active=row.get('status_ar', '').strip() == 'Ø¹Ù„Ù‰ Ø±Ø£Ø³ Ø§Ù„Ø¹Ù…Ù„',
                        created_at=now,
                        updated_at=now
                    )
                    db.add(doctor)
                    doctors_added += 1
            
            db.commit()
            counts["doctors"] = doctors_added
            logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {doctors_added} Ø·Ø¨ÙŠØ¨")
        
        # 3. Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
        if services_file:
            logger.info("ğŸ“‚ Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø®Ø¯Ù…Ø§Øª...")
            content = await services_file.read()
            csv_content = content.decode('utf-8-sig')
            reader = csv.DictReader(io.StringIO(csv_content))
            
            services_added = 0
            for row in reader:
                service_name = row.get('name_ar', '').strip()
                if not service_name:
                    continue
                
                existing = db.query(Service).filter(Service.name == service_name).first()
                if not existing:
                    price_str = row.get('price_sar', '').strip()
                    base_price = None
                    if price_str:
                        try:
                            base_price = float(price_str)
                        except ValueError:
                            pass
                    
                    service = Service(
                        id=uuid.uuid4(),
                        name=service_name,
                        description=row.get('description_ar', '').strip() or row.get('notes', '').strip(),
                        base_price=base_price,
                        is_active=True,
                        created_at=now,
                        updated_at=now
                    )
                    db.add(service)
                    services_added += 1
            
            db.commit()
            counts["services"] = services_added
            logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {services_added} Ø®Ø¯Ù…Ø©")
        
        summary = f"""
âœ… ØªÙ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª CSV Ø¨Ù†Ø¬Ø§Ø­!

ğŸ“Š Ø§Ù„Ù…Ù„Ø®Øµ:
- Ø§Ù„ÙØ±ÙˆØ¹ Ø§Ù„Ù…Ø¶Ø§ÙØ©: {counts.get('branches', 0)}
- Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ Ø§Ù„Ù…Ø¶Ø§ÙÙˆÙ†: {counts.get('doctors', 0)}
- Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø¶Ø§ÙØ©: {counts.get('services', 0)}
        """
        
        return {
            "success": True,
            "message": summary.strip(),
            "details": {"counts": counts}
        }
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        error_msg = str(e)
        logger.error(f"âŒ ÙØ´Ù„ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† CSV: {error_msg}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {error_msg[:200]}"
        )

