"""
Database Management Router - Ø¥Ø¯Ø§Ø±Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
"""
import logging
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from sqlalchemy import create_engine, text, inspect as sqlalchemy_inspect
from pydantic import BaseModel
from typing import Dict, Any, List
from app.db.session import get_db
from app.middleware.auth import verify_api_key
from app.config import get_settings
from app.db.base import Base

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/admin/db", tags=["Admin - Database"])

settings = get_settings()


class InitDBResponse(BaseModel):
    """Ø±Ø¯ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    success: bool
    message: str
    details: Dict[str, Any] = {}


class CleanDBResponse(BaseModel):
    """Ø±Ø¯ ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    success: bool
    message: str
    deleted_counts: Dict[str, int] = {}


class DropTablesResponse(BaseModel):
    """Ø±Ø¯ Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„"""
    success: bool
    message: str
    dropped_tables: List[str] = []


class AddSampleDataResponse(BaseModel):
    """Ø±Ø¯ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©"""
    success: bool
    message: str
    details: Dict[str, Any] = {}




@router.post("/init", response_model=InitDBResponse)
async def init_database(
    db: Session = Depends(get_db),
    api_key: str = Depends(verify_api_key)
):
    """
    ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØ§Ù„Ù€ indexes
    """
    logger.info("Ø¨Ø¯Ø¡ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    
    try:
        details = {}
        
        # 1. ØªØ«Ø¨ÙŠØª pgvector extension (Ø§Ø®ØªÙŠØ§Ø±ÙŠ - Ù„Ù… Ù†Ø¹Ø¯ Ù†Ø³ØªØ®Ø¯Ù…Ù‡ Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© RAG)
        logger.info("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† pgvector extension (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)...")
        pgvector_engine = create_engine(
            settings.DATABASE_URL,
            isolation_level="AUTOCOMMIT"
        )
        
        try:
            with pgvector_engine.connect() as conn:
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ extension
                check_query = text("""
                    SELECT EXISTS(
                        SELECT 1 FROM pg_extension WHERE extname = 'vector'
                    )
                """)
                result = conn.execute(check_query)
                exists = result.scalar()
                
                if not exists:
                    install_query = text("CREATE EXTENSION IF NOT EXISTS vector")
                    conn.execute(install_query)
                    details["pgvector"] = "ØªÙ… Ø§Ù„ØªØ«Ø¨ÙŠØª"
                    logger.info("âœ… ØªÙ… ØªØ«Ø¨ÙŠØª pgvector extension")
                else:
                    details["pgvector"] = "Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„"
                    logger.info("âœ… pgvector extension Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„")
        except Exception as e:
            # pgvector ØºÙŠØ± Ù…ØªÙˆÙØ± - Ù‡Ø°Ø§ Ù…Ù‚Ø¨ÙˆÙ„ Ù„Ø£Ù†Ù†Ø§ Ù„Ø§ Ù†Ø³ØªØ®Ø¯Ù…Ù‡ Ø¨Ø¹Ø¯ Ø§Ù„Ø¢Ù†
            details["pgvector"] = f"ØºÙŠØ± Ù…ØªÙˆÙØ± (Ù‡Ø°Ø§ Ù…Ù‚Ø¨ÙˆÙ„): {str(e)[:100]}"
            logger.warning(f"âš ï¸  ØªØ­Ø°ÙŠØ±: pgvector ØºÙŠØ± Ù…ØªÙˆÙØ± (Ù‡Ø°Ø§ Ù…Ù‚Ø¨ÙˆÙ„ - Ù„Ù… Ù†Ø¹Ø¯ Ù†Ø³ØªØ®Ø¯Ù…Ù‡): {str(e)[:100]}")
        
        # 2. Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        logger.info("Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„...")
        Base.metadata.create_all(bind=pgvector_engine)
        details["tables"] = "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„"
        logger.info("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¨Ù†Ø¬Ø§Ø­")
        
        # 2.5. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
        logger.info("Ø¬Ø§Ø±ÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©...")
        inspector = sqlalchemy_inspect(pgvector_engine)
        migration_results = []
        
        with pgvector_engine.connect() as conn:
            # ØªØ­Ø¯ÙŠØ« Ø¬Ø¯ÙˆÙ„ conversations
            if "conversations" in inspector.get_table_names():
                conv_columns = [col["name"] for col in inspector.get_columns("conversations")]
                logger.info(f"ğŸ“‹ Ø£Ø¹Ù…Ø¯Ø© conversations Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {', '.join(conv_columns)}")
                
                if "user_message" not in conv_columns:
                    logger.info("â• Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ user_message Ù„Ø¬Ø¯ÙˆÙ„ conversations...")
                    try:
                        conn.execute(text("ALTER TABLE conversations ADD COLUMN user_message TEXT"))
                        migration_results.append("ØªÙ… Ø¥Ø¶Ø§ÙØ© user_message Ù„Ù€ conversations")
                        logger.info("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© user_message")
                    except Exception as e:
                        error_msg = str(e)
                        if "already exists" in error_msg.lower() or "duplicate" in error_msg.lower():
                            logger.info("â„¹ï¸  Ø§Ù„Ø¹Ù…ÙˆØ¯ user_message Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„")
                        else:
                            logger.warning(f"âš ï¸  Ù„Ù… ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© user_message: {error_msg[:100]}")
                
                if "bot_reply" not in conv_columns:
                    logger.info("â• Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ bot_reply Ù„Ø¬Ø¯ÙˆÙ„ conversations...")
                    try:
                        conn.execute(text("ALTER TABLE conversations ADD COLUMN bot_reply TEXT"))
                        migration_results.append("ØªÙ… Ø¥Ø¶Ø§ÙØ© bot_reply Ù„Ù€ conversations")
                        logger.info("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© bot_reply")
                    except Exception as e:
                        error_msg = str(e)
                        if "already exists" in error_msg.lower() or "duplicate" in error_msg.lower():
                            logger.info("â„¹ï¸  Ø§Ù„Ø¹Ù…ÙˆØ¯ bot_reply Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„")
                        else:
                            logger.warning(f"âš ï¸  Ù„Ù… ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© bot_reply: {error_msg[:100]}")
            
            # ØªØ­Ø¯ÙŠØ« Ø¬Ø¯ÙˆÙ„ doctors
            if "doctors" in inspector.get_table_names():
                doctors_columns = [col["name"] for col in inspector.get_columns("doctors")]
                logger.info(f"ğŸ“‹ Ø£Ø¹Ù…Ø¯Ø© doctors Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {', '.join(doctors_columns)}")
                
                new_doctor_columns = {
                    "license_number": "VARCHAR",
                    "phone_number": "VARCHAR",
                    "email": "VARCHAR",
                    "qualifications": "TEXT",
                    "experience_years": "VARCHAR",
                    "working_hours": "JSONB"
                }
                
                for col_name, col_type in new_doctor_columns.items():
                    if col_name not in doctors_columns:
                        logger.info(f"â• Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ {col_name} Ù„Ø¬Ø¯ÙˆÙ„ doctors...")
                        try:
                            conn.execute(text(f"ALTER TABLE doctors ADD COLUMN {col_name} {col_type}"))
                            migration_results.append(f"ØªÙ… Ø¥Ø¶Ø§ÙØ© {col_name} Ù„Ù€ doctors")
                            logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {col_name}")
                        except Exception as e:
                            error_msg = str(e)
                            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„ØŒ Ù†ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø®Ø·Ø£
                            if "already exists" in error_msg.lower() or "duplicate" in error_msg.lower():
                                logger.info(f"â„¹ï¸  Ø§Ù„Ø¹Ù…ÙˆØ¯ {col_name} Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„")
                            else:
                                logger.warning(f"âš ï¸  Ù„Ù… ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© {col_name}: {error_msg[:100]}")
            
            # ØªØ­Ø¯ÙŠØ« Ø¬Ø¯ÙˆÙ„ appointments
            if "appointments" in inspector.get_table_names():
                appointments_columns = [col["name"] for col in inspector.get_columns("appointments")]
                logger.info(f"ğŸ“‹ Ø£Ø¹Ù…Ø¯Ø© appointments Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {', '.join(appointments_columns)}")
                
                if "patient_id" not in appointments_columns:
                    logger.info("â• Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ patient_id Ù„Ø¬Ø¯ÙˆÙ„ appointments...")
                    try:
                        conn.execute(text("ALTER TABLE appointments ADD COLUMN patient_id UUID"))
                        migration_results.append("ØªÙ… Ø¥Ø¶Ø§ÙØ© patient_id Ù„Ù€ appointments")
                        logger.info("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© patient_id")
                    except Exception as e:
                        error_msg = str(e)
                        if "already exists" in error_msg.lower() or "duplicate" in error_msg.lower():
                            logger.info("â„¹ï¸  Ø§Ù„Ø¹Ù…ÙˆØ¯ patient_id Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„")
                        else:
                            logger.warning(f"âš ï¸  Ù„Ù… ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© patient_id: {error_msg[:100]}")
                
                if "appointment_type" not in appointments_columns:
                    logger.info("â• Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ appointment_type Ù„Ø¬Ø¯ÙˆÙ„ appointments...")
                    try:
                        conn.execute(text("ALTER TABLE appointments ADD COLUMN appointment_type VARCHAR"))
                        migration_results.append("ØªÙ… Ø¥Ø¶Ø§ÙØ© appointment_type Ù„Ù€ appointments")
                        logger.info("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© appointment_type")
                    except Exception as e:
                        error_msg = str(e)
                        if "already exists" in error_msg.lower() or "duplicate" in error_msg.lower():
                            logger.info("â„¹ï¸  Ø§Ù„Ø¹Ù…ÙˆØ¯ appointment_type Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„")
                        else:
                            logger.warning(f"âš ï¸  Ù„Ù… ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© appointment_type: {error_msg[:100]}")
        
        if migration_results:
            details["migrations"] = migration_results
            logger.info(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« {len(migration_results)} Ø¬Ø¯ÙˆÙ„/Ø¹Ù…ÙˆØ¯")
        else:
            details["migrations"] = "Ù„Ø§ ØªÙˆØ¬Ø¯ ØªØ­Ø¯ÙŠØ«Ø§Øª Ù…Ø·Ù„ÙˆØ¨Ø©"
            logger.info("âœ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ø­Ø¯Ø«Ø©")
        
        # 3. Ø¥Ù†Ø´Ø§Ø¡ indexes Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
        logger.info("Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ indexes...")
        index_results = []
        with pgvector_engine.connect() as conn:
            indexes = [
                {
                    "name": "idx_conversations_user_channel_created",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_conversations_user_channel_created 
                    ON conversations(user_id, channel, created_at DESC)
                    """
                },
                {
                    "name": "idx_branches_is_active",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_branches_is_active 
                    ON branches(is_active) WHERE is_active = true
                    """
                },
                {
                    "name": "idx_services_is_active",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_services_is_active 
                    ON services(is_active) WHERE is_active = true
                    """
                },
                {
                    "name": "idx_doctors_is_active",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_doctors_is_active 
                    ON doctors(is_active) WHERE is_active = true
                    """
                },
                {
                    "name": "idx_faqs_is_active",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_faqs_is_active 
                    ON faqs(is_active) WHERE is_active = true
                    """
                },
                {
                    "name": "idx_offers_is_active",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_offers_is_active 
                    ON offers(is_active) WHERE is_active = true
                    """
                },
                {
                    "name": "idx_document_chunks_document_id",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_document_chunks_document_id 
                    ON document_chunks(document_id)
                    """
                },
                # Indexes Ù„Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØ§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
                {
                    "name": "idx_conversations_created_at",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_conversations_created_at 
                    ON conversations(created_at DESC)
                    """
                },
                {
                    "name": "idx_conversations_channel",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_conversations_channel 
                    ON conversations(channel)
                    """
                },
                {
                    "name": "idx_conversations_intent",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_conversations_intent 
                    ON conversations(intent)
                    """
                },
                {
                    "name": "idx_conversations_satisfaction",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_conversations_satisfaction 
                    ON conversations(satisfaction_score) WHERE satisfaction_score IS NOT NULL
                    """
                },
                {
                    "name": "idx_appointments_datetime",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_appointments_datetime 
                    ON appointments(datetime)
                    """
                },
                {
                    "name": "idx_appointments_status",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_appointments_status 
                    ON appointments(status)
                    """
                },
                {
                    "name": "idx_appointments_patient_id",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_appointments_patient_id 
                    ON appointments(patient_id) WHERE patient_id IS NOT NULL
                    """
                },
                {
                    "name": "idx_patients_phone_number",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_patients_phone_number 
                    ON patients(phone_number)
                    """
                },
                {
                    "name": "idx_treatments_patient_id",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_treatments_patient_id 
                    ON treatments(patient_id)
                    """
                },
                {
                    "name": "idx_treatments_treatment_date",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_treatments_treatment_date 
                    ON treatments(treatment_date DESC)
                    """
                },
                {
                    "name": "idx_invoices_patient_id",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_invoices_patient_id 
                    ON invoices(patient_id)
                    """
                },
                {
                    "name": "idx_invoices_payment_status",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_invoices_payment_status 
                    ON invoices(payment_status)
                    """
                },
                {
                    "name": "idx_invoices_invoice_date",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_invoices_invoice_date 
                    ON invoices(invoice_date DESC)
                    """
                },
                {
                    "name": "idx_employees_position",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_employees_position 
                    ON employees(position)
                    """
                },
                {
                    "name": "idx_doctors_license_number",
                    "sql": """
                    CREATE INDEX IF NOT EXISTS idx_doctors_license_number 
                    ON doctors(license_number) WHERE license_number IS NOT NULL
                    """
                },
            ]
            
            created_count = 0
            for index in indexes:
                try:
                    conn.execute(text(index["sql"]))
                    index_results.append({"name": index["name"], "status": "ØªÙ… Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡"})
                    created_count += 1
                except Exception as e:
                    index_results.append({"name": index["name"], "status": f"Ø®Ø·Ø£: {str(e)[:100]}"})
                    logger.warning(f"âš ï¸  ØªØ­Ø°ÙŠØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ index {index['name']}: {str(e)[:100]}")
            
            details["indexes"] = {
                "total": len(indexes),
                "created": created_count,
                "results": index_results
            }
            logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {created_count} Ù…Ù† Ø£ØµÙ„ {len(indexes)} indexes")
        
        return InitDBResponse(
            success=True,
            message="ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­",
            details=details
        )
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"âŒ ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {error_msg}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {error_msg[:200]}"
        )


@router.post("/clean", response_model=CleanDBResponse)
async def clean_database(
    db: Session = Depends(get_db),
    api_key: str = Depends(verify_api_key)
):
    """
    ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
    âš ï¸ ØªØ­Ø°ÙŠØ±: Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¹Ù†Ù‡Ø§!
    Ø³ÙŠØªÙ… Ø­Ø°Ù ÙƒÙ„ Ø´ÙŠØ¡ ØªÙ…Ø§Ù…Ø§Ù‹ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!
    """
    logger.warning("âš ï¸  Ø¨Ø¯Ø¡ ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Ø³ÙŠØªÙ… Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ…Ø§Ù…Ø§Ù‹!")
    
    try:
        from app.db.models import (
            Conversation, DocumentChunk, DocumentSource,
            Service, Doctor, Branch, Offer, FAQ,
            Appointment, UnansweredQuestion, PendingHandoff,
            Patient, Treatment, Invoice, Employee
        )
        from sqlalchemy import text
        
        deleted_counts = {}
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… TRUNCATE CASCADE Ù„Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ ÙˆØ£Ø³Ø±Ø¹
        # TRUNCATE ÙŠØ­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙŠØ¹ÙŠØ¯ reset Ù„Ù„Ù€ sequences
        
        logger.info("ğŸ—‘ï¸  Ø¨Ø¯Ø¡ Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… TRUNCATE CASCADE...")
        
        # ØªØ¹Ø·ÙŠÙ„ Foreign Key Constraints Ù…Ø¤Ù‚ØªØ§Ù‹
        db.execute(text("SET session_replication_role = 'replica'"))
        db.commit()
        
        # Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„ØµØ­ÙŠØ­
        tables_to_truncate = [
            ("treatments", "Ø§Ù„Ø¹Ù„Ø§Ø¬Ø§Øª"),
            ("invoices", "Ø§Ù„ÙÙˆØ§ØªÙŠØ±"),
            ("appointments", "Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯"),
            ("document_chunks", "Document Chunks"),
            ("document_sources", "Document Sources"),
            ("unanswered_questions", "Unanswered Questions"),
            ("pending_handoffs", "Pending Handoffs"),
            ("conversations", "Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª"),
            ("offers", "Ø§Ù„Ø¹Ø±ÙˆØ¶"),
            ("doctors", "Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡"),
            ("services", "Ø§Ù„Ø®Ø¯Ù…Ø§Øª"),
            ("branches", "Ø§Ù„ÙØ±ÙˆØ¹"),
            ("patients", "Ø§Ù„Ù…Ø±Ø¶Ù‰"),
            ("employees", "Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†"),
            ("faqs", "Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©"),
        ]
        
        # Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        for table_name, table_label in tables_to_truncate:
            try:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… TRUNCATE CASCADE Ù„Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                result = db.execute(text(f"TRUNCATE TABLE {table_name} CASCADE"))
                db.commit()
                
                # Ø¬Ù„Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø°Ù (Ù„Ù„Ø¹Ø±Ø¶)
                count_result = db.execute(text(f"SELECT COUNT(*) FROM {table_name}"))
                count = count_result.scalar()
                
                deleted_counts[table_name] = count
                logger.info(f"âœ… ØªÙ… Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¬Ø¯ÙˆÙ„ {table_label} ({table_name})")
            except Exception as e:
                # Ø¥Ø°Ø§ ÙØ´Ù„ TRUNCATEØŒ Ø¬Ø±Ø¨ DELETE
                try:
                    logger.warning(f"âš ï¸  TRUNCATE ÙØ´Ù„ Ù„Ù€ {table_name}ØŒ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… DELETE...")
                    if table_name == "treatments":
                        count = db.query(Treatment).delete()
                    elif table_name == "invoices":
                        count = db.query(Invoice).delete()
                    elif table_name == "appointments":
                        count = db.query(Appointment).delete()
                    elif table_name == "document_chunks":
                        count = db.query(DocumentChunk).delete()
                    elif table_name == "document_sources":
                        count = db.query(DocumentSource).delete()
                    elif table_name == "unanswered_questions":
                        count = db.query(UnansweredQuestion).delete()
                    elif table_name == "pending_handoffs":
                        count = db.query(PendingHandoff).delete()
                    elif table_name == "conversations":
                        count = db.query(Conversation).delete()
                    elif table_name == "offers":
                        count = db.query(Offer).delete()
                    elif table_name == "doctors":
                        count = db.query(Doctor).delete()
                    elif table_name == "services":
                        count = db.query(Service).delete()
                    elif table_name == "branches":
                        count = db.query(Branch).delete()
                    elif table_name == "patients":
                        count = db.query(Patient).delete()
                    elif table_name == "employees":
                        count = db.query(Employee).delete()
                    elif table_name == "faqs":
                        count = db.query(FAQ).delete()
                    else:
                        count = 0
                    
                    db.commit()
                    deleted_counts[table_name] = count
                    logger.info(f"âœ… ØªÙ… Ø­Ø°Ù {count} Ø³Ø¬Ù„ Ù…Ù† Ø¬Ø¯ÙˆÙ„ {table_label} ({table_name})")
                except Exception as delete_error:
                    logger.error(f"âŒ ÙØ´Ù„ Ø­Ø°Ù {table_name}: {str(delete_error)}")
                    deleted_counts[table_name] = 0
        
        # Ø¥Ø¹Ø§Ø¯Ø© ØªÙØ¹ÙŠÙ„ Foreign Key Constraints
        db.execute(text("SET session_replication_role = 'origin'"))
        db.commit()
        
        total_deleted = sum(deleted_counts.values())
        
        logger.info(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©: {total_deleted}")
        logger.info(f"ğŸ“Š Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©: {', '.join(deleted_counts.keys())}")
        
        return CleanDBResponse(
            success=True,
            message=f"âœ… ØªÙ… Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ…Ø§Ù…Ø§Ù‹!\n\nØ¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©: {total_deleted}",
            deleted_counts=deleted_counts
        )
        
    except Exception as e:
        db.rollback()
        error_msg = str(e)
        logger.error(f"âŒ ÙØ´Ù„ ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {error_msg}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {error_msg[:200]}"
        )


@router.post("/drop-all-tables", response_model=DropTablesResponse)
async def drop_all_tables(
    db: Session = Depends(get_db),
    api_key: str = Depends(verify_api_key)
):
    """
    Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (DROP TABLE)
    âš ï¸âš ï¸âš ï¸ ØªØ­Ø°ÙŠØ± Ø®Ø·ÙŠØ±: Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© ØªØ­Ø°Ù Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ù†ÙØ³Ù‡Ø§ ÙˆÙ„ÙŠØ³ ÙÙ‚Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!
    âš ï¸âš ï¸âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¹Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©!
    Ø¨Ø¹Ø¯ Ø§Ù„Ø­Ø°ÙØŒ ÙŠØ¬Ø¨ ØªØ´ØºÙŠÙ„ /admin/db/init Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
    """
    logger.critical("ğŸš¨ğŸš¨ğŸš¨ Ø¨Ø¯Ø¡ Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Ø¹Ù…Ù„ÙŠØ© Ø®Ø·ÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹!")
    
    try:
        from sqlalchemy import text, inspect as sqlalchemy_inspect
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø±Ùƒ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… AUTOCOMMIT Ù„ØªØ¬Ù†Ø¨ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù€ transactions
        engine = create_engine(settings.DATABASE_URL, isolation_level="AUTOCOMMIT")
        inspector = sqlalchemy_inspect(engine)
        
        # Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        all_tables = inspector.get_table_names()
        
        if not all_tables:
            return DropTablesResponse(
                success=True,
                message="Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¬Ø¯Ø§ÙˆÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
                dropped_tables=[]
            )
        
        dropped_tables = []
        
        # Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… DROP TABLE CASCADE Ù„Ø­Ø°Ù Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØ§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        # CASCADE ÙŠØ­Ø°Ù Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø© (Foreign Keys) ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        # Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„ØªØ¹Ø·ÙŠÙ„ Foreign Keys Ù„Ø£Ù† CASCADE ÙŠØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡Ø§
        with engine.connect() as conn:
            # Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ø¨Ø§Ø´Ø±Ø©
            # CASCADE Ø³ÙŠØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Foreign Keys ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
            for table_name in all_tables:
                try:
                    # DROP TABLE CASCADE ÙŠØ­Ø°Ù Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
                    conn.execute(text(f"DROP TABLE IF EXISTS {table_name} CASCADE"))
                    dropped_tables.append(table_name)
                    logger.warning(f"ğŸ—‘ï¸  ØªÙ… Ø­Ø°Ù Ø¬Ø¯ÙˆÙ„: {table_name}")
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ Ø­Ø°Ù Ø¬Ø¯ÙˆÙ„ {table_name}: {str(e)}")
                    # Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ù…Ø¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø£Ø®Ø±Ù‰ Ø­ØªÙ‰ Ù„Ùˆ ÙØ´Ù„ Ø£Ø­Ø¯Ù‡Ø§
        
        logger.critical(f"ğŸš¨ ØªÙ… Ø­Ø°Ù {len(dropped_tables)} Ø¬Ø¯ÙˆÙ„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!")
        
        return DropTablesResponse(
            success=True,
            message=f"âœ… ØªÙ… Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!\n\nØªÙ… Ø­Ø°Ù {len(dropped_tables)} Ø¬Ø¯ÙˆÙ„",
            dropped_tables=dropped_tables
        )
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"âŒ ÙØ´Ù„ Ø­Ø°Ù Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„: {error_msg}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ Ø­Ø°Ù Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„: {error_msg[:200]}"
        )


@router.post("/add-sample-data", response_model=AddSampleDataResponse)
async def add_sample_data(
    db: Session = Depends(get_db),
    api_key: str = Depends(verify_api_key)
):
    """
    Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    """
    logger.info("Ø¨Ø¯Ø¡ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©...")
    
    try:
        from app.db.models import Branch, Doctor, Service, Offer, FAQ, Patient, Employee
        from datetime import datetime, timedelta, date
        import uuid
        
        details = {}
        counts = {}
        
        # 1. Ø¥Ø¶Ø§ÙØ© ÙØ±ÙˆØ¹ Ø¹ÙŠØ§Ø¯Ø§Øª Ø¹Ø§Ø¯Ù„ ÙƒÙŠØ±
        branches_data = [
            {
                "name": "Ø¹ÙŠØ§Ø¯Ø§Øª Ø¹Ø§Ø¯Ù„ ÙƒÙŠØ± - ÙØ±Ø¹ Ø§Ù„Ø±ÙŠØ§Ø¶",
                "city": "Ø§Ù„Ø±ÙŠØ§Ø¶",
                "address": "Ø­ÙŠ Ø§Ù„Ø¹Ù„ÙŠØ§ØŒ Ø·Ø±ÙŠÙ‚ Ø§Ù„Ù…Ù„Ùƒ ÙÙ‡Ø¯",
                "phone": "0112345678",
                "location_url": "https://maps.google.com/?q=24.7136,46.6753",
                "working_hours": {
                    "sunday": {"from": "9:00", "to": "21:00"},
                    "monday": {"from": "9:00", "to": "21:00"},
                    "tuesday": {"from": "9:00", "to": "21:00"},
                    "wednesday": {"from": "9:00", "to": "21:00"},
                    "thursday": {"from": "9:00", "to": "21:00"},
                    "friday": {"from": "14:00", "to": "22:00"},
                    "saturday": {"from": "9:00", "to": "21:00"}
                }
            },
            {
                "name": "Ø¹ÙŠØ§Ø¯Ø§Øª Ø¹Ø§Ø¯Ù„ ÙƒÙŠØ± - ÙØ±Ø¹ Ø¬Ø¯Ø©",
                "city": "Ø¬Ø¯Ø©",
                "address": "Ø­ÙŠ Ø§Ù„Ø²Ù‡Ø±Ø§Ø¡ØŒ Ø´Ø§Ø±Ø¹ Ø§Ù„ØªØ­Ù„ÙŠØ©",
                "phone": "0123456789",
                "location_url": "https://maps.google.com/?q=21.5433,39.1728",
                "working_hours": {
                    "sunday": {"from": "9:00", "to": "21:00"},
                    "monday": {"from": "9:00", "to": "21:00"},
                    "tuesday": {"from": "9:00", "to": "21:00"},
                    "wednesday": {"from": "9:00", "to": "21:00"},
                    "thursday": {"from": "9:00", "to": "21:00"},
                    "friday": {"from": "14:00", "to": "22:00"},
                    "saturday": {"from": "9:00", "to": "21:00"}
                }
            }
        ]
        
        branches = []
        now = datetime.now()
        for branch_data in branches_data:
            branch = Branch(
                id=uuid.uuid4(),
                name=branch_data["name"],
                city=branch_data["city"],
                address=branch_data["address"],
                phone=branch_data["phone"],
                location_url=branch_data.get("location_url"),
                working_hours=branch_data["working_hours"],
                is_active=True,
                created_at=now,
                updated_at=now
            )
            db.add(branch)
            branches.append(branch)
        
        db.commit()
        for branch in branches:
            db.refresh(branch)
        counts["branches"] = len(branches)
        details["branches"] = [b.name for b in branches]
        logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {len(branches)} ÙØ±Ø¹")
        
        # 2. Ø¥Ø¶Ø§ÙØ© Ø£Ø·Ø¨Ø§Ø¡ Ø¹ÙŠØ§Ø¯Ø§Øª Ø¹Ø§Ø¯Ù„ ÙƒÙŠØ±
        doctors_data = [
            {
                "name": "Ø¯. Ø¹Ø§Ø¯Ù„ ÙƒÙŠØ±",
                "specialty": "Ø·Ø¨ Ø§Ù„Ø¹Ø§Ø¦Ù„Ø©",
                "license_number": "SA-MED-001",
                "phone_number": "0501234567",
                "email": "dr.adele@adelecare.com",
                "bio": "Ø§Ø³ØªØ´Ø§Ø±ÙŠ Ø·Ø¨ Ø§Ù„Ø¹Ø§Ø¦Ù„Ø© Ù…Ø¹ Ø®Ø¨Ø±Ø© ØªØ²ÙŠØ¯ Ø¹Ù† 15 Ø¹Ø§Ù…Ø§Ù‹ ÙÙŠ Ø§Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„ØµØ­ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø©",
                "qualifications": "Ø¯ÙƒØªÙˆØ±Ø§Ù‡ ÙÙŠ Ø§Ù„Ø·Ø¨ Ù…Ù† Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ù„Ùƒ Ø³Ø¹ÙˆØ¯ØŒ Ø²Ù…Ø§Ù„Ø© Ø·Ø¨ Ø§Ù„Ø¹Ø§Ø¦Ù„Ø©",
                "experience_years": "15",
                "working_hours": {
                    "sunday": {"from": "9:00", "to": "17:00"},
                    "monday": {"from": "9:00", "to": "17:00"},
                    "tuesday": {"from": "9:00", "to": "17:00"},
                    "wednesday": {"from": "9:00", "to": "17:00"},
                    "thursday": {"from": "9:00", "to": "17:00"}
                },
                "branch_id": branches[0].id if branches else None
            },
            {
                "name": "Ø¯. ÙØ§Ø·Ù…Ø© Ø£Ø­Ù…Ø¯",
                "specialty": "Ø·Ø¨ Ø§Ù„Ø£Ø·ÙØ§Ù„",
                "license_number": "SA-MED-002",
                "phone_number": "0502345678",
                "email": "dr.fatima@adelecare.com",
                "bio": "Ø§Ø³ØªØ´Ø§Ø±ÙŠØ© Ø·Ø¨ Ø§Ù„Ø£Ø·ÙØ§Ù„ Ù…ØªØ®ØµØµØ© ÙÙŠ Ø±Ø¹Ø§ÙŠØ© Ø§Ù„Ø£Ø·ÙØ§Ù„ Ù…Ù† Ø§Ù„ÙˆÙ„Ø§Ø¯Ø© Ø­ØªÙ‰ Ø§Ù„Ù…Ø±Ø§Ù‡Ù‚Ø©",
                "qualifications": "Ø¯ÙƒØªÙˆØ±Ø§Ù‡ ÙÙŠ Ø·Ø¨ Ø§Ù„Ø£Ø·ÙØ§Ù„ØŒ Ø²Ù…Ø§Ù„Ø© Ø·Ø¨ Ø§Ù„Ø£Ø·ÙØ§Ù„",
                "experience_years": "12",
                "working_hours": {
                    "sunday": {"from": "10:00", "to": "18:00"},
                    "monday": {"from": "10:00", "to": "18:00"},
                    "tuesday": {"from": "10:00", "to": "18:00"},
                    "wednesday": {"from": "10:00", "to": "18:00"},
                    "thursday": {"from": "10:00", "to": "18:00"}
                },
                "branch_id": branches[0].id if branches else None
            },
            {
                "name": "Ø¯. Ù…Ø­Ù…Ø¯ Ø§Ù„Ø³Ø§Ù„Ù…",
                "specialty": "Ø·Ø¨ Ø§Ù„Ø¨Ø§Ø·Ù†Ø©",
                "license_number": "SA-MED-003",
                "phone_number": "0503456789",
                "email": "dr.mohammed@adelecare.com",
                "bio": "Ø§Ø³ØªØ´Ø§Ø±ÙŠ Ø·Ø¨ Ø§Ù„Ø¨Ø§Ø·Ù†Ø© Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù…Ø²Ù…Ù†Ø© ÙˆØ§Ù„ÙˆÙ‚Ø§ÙŠØ©",
                "qualifications": "Ø¯ÙƒØªÙˆØ±Ø§Ù‡ ÙÙŠ Ø§Ù„Ø·Ø¨ Ø§Ù„Ø¨Ø§Ø·Ù†ÙŠØŒ Ø²Ù…Ø§Ù„Ø© Ø·Ø¨ Ø§Ù„Ø¨Ø§Ø·Ù†Ø©",
                "experience_years": "18",
                "working_hours": {
                    "sunday": {"from": "8:00", "to": "16:00"},
                    "monday": {"from": "8:00", "to": "16:00"},
                    "tuesday": {"from": "8:00", "to": "16:00"},
                    "wednesday": {"from": "8:00", "to": "16:00"},
                    "thursday": {"from": "8:00", "to": "16:00"}
                },
                "branch_id": branches[1].id if len(branches) > 1 else (branches[0].id if branches else None)
            }
        ]
        
        doctors = []
        for doctor_data in doctors_data:
            doctor = Doctor(
                id=uuid.uuid4(),
                name=doctor_data["name"],
                specialty=doctor_data["specialty"],
                license_number=doctor_data.get("license_number"),
                branch_id=doctor_data["branch_id"],
                phone_number=doctor_data.get("phone_number"),
                email=doctor_data.get("email"),
                bio=doctor_data["bio"],
                qualifications=doctor_data.get("qualifications"),
                experience_years=doctor_data.get("experience_years"),
                working_hours=doctor_data.get("working_hours"),
                is_active=True,
                created_at=now,
                updated_at=now
            )
            db.add(doctor)
            doctors.append(doctor)
        
        db.commit()
        for doctor in doctors:
            db.refresh(doctor)
        counts["doctors"] = len(doctors)
        details["doctors"] = [d.name for d in doctors]
        logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {len(doctors)} Ø·Ø¨ÙŠØ¨")
        
        # 3. Ø¥Ø¶Ø§ÙØ© Ø®Ø¯Ù…Ø§Øª Ø¹ÙŠØ§Ø¯Ø§Øª Ø¹Ø§Ø¯Ù„ ÙƒÙŠØ±
        services_data = [
            {
                "name": "Ø§Ø³ØªØ´Ø§Ø±Ø© Ø·Ø¨ÙŠØ© Ø¹Ø§Ù…Ø©",
                "base_price": 200.0,
                "description": "Ø§Ø³ØªØ´Ø§Ø±Ø© Ø·Ø¨ÙŠØ© Ø´Ø§Ù…Ù„Ø© Ù…Ø¹ Ø·Ø¨ÙŠØ¨ Ø§Ù„Ø¹Ø§Ø¦Ù„Ø©"
            },
            {
                "name": "Ø§Ø³ØªØ´Ø§Ø±Ø© Ø·Ø¨ Ø§Ù„Ø£Ø·ÙØ§Ù„",
                "base_price": 250.0,
                "description": "Ø§Ø³ØªØ´Ø§Ø±Ø© Ù…ØªØ®ØµØµØ© Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„Ø£Ø·ÙØ§Ù„"
            },
            {
                "name": "ÙØ­Øµ Ø¯ÙˆØ±ÙŠ Ø´Ø§Ù…Ù„",
                "base_price": 500.0,
                "description": "ÙØ­Øµ Ø·Ø¨ÙŠ Ø´Ø§Ù…Ù„ ÙŠØªØ¶Ù…Ù† ØªØ­Ø§Ù„ÙŠÙ„ ÙˆÙØ­ÙˆØµØ§Øª Ø£Ø³Ø§Ø³ÙŠØ©"
            },
            {
                "name": "Ù…ØªØ§Ø¨Ø¹Ø© Ø­Ø§Ù„Ø© Ù…Ø²Ù…Ù†Ø©",
                "base_price": 150.0,
                "description": "Ù…ØªØ§Ø¨Ø¹Ø© Ø¯ÙˆØ±ÙŠØ© Ù„Ù„Ù…Ø±Ø¶Ù‰ Ø§Ù„Ø°ÙŠÙ† ÙŠØ¹Ø§Ù†ÙˆÙ† Ù…Ù† Ø£Ù…Ø±Ø§Ø¶ Ù…Ø²Ù…Ù†Ø©"
            },
            {
                "name": "ÙØ­Øµ Ø·Ø¨ÙŠ Ù„Ù„ØªÙˆØ¸ÙŠÙ",
                "base_price": 300.0,
                "description": "ÙØ­Øµ Ø·Ø¨ÙŠ Ø´Ø§Ù…Ù„ Ù„Ù„ØªÙˆØ¸ÙŠÙ"
            },
            {
                "name": "ØªØ·Ø¹ÙŠÙ…Ø§Øª",
                "base_price": 100.0,
                "description": "ØªØ·Ø¹ÙŠÙ…Ø§Øª Ù„Ù„Ø£Ø·ÙØ§Ù„ ÙˆØ§Ù„ÙƒØ¨Ø§Ø±"
            }
        ]
        
        services = []
        for service_data in services_data:
            service = Service(
                id=uuid.uuid4(),
                name=service_data["name"],
                base_price=service_data["base_price"],
                description=service_data["description"],
                is_active=True,
                created_at=now,
                updated_at=now
            )
            db.add(service)
            services.append(service)
        
        db.commit()
        for service in services:
            db.refresh(service)
        counts["services"] = len(services)
        details["services"] = [s.name for s in services]
        logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {len(services)} Ø®Ø¯Ù…Ø©")
        
        # 4. Ø¥Ø¶Ø§ÙØ© Ø¹Ø±ÙˆØ¶
        offers_data = []
        if services:
            offers_data = [
                {
                    "title": "Ø¹Ø±Ø¶ Ø®Ø§Øµ Ø¹Ù„Ù‰ ØªØ¨ÙŠÙŠØ¶ Ø§Ù„Ø£Ø³Ù†Ø§Ù†",
                    "description": "Ø®ØµÙ… 20% Ø¹Ù„Ù‰ ØªØ¨ÙŠÙŠØ¶ Ø§Ù„Ø£Ø³Ù†Ø§Ù† Ù„Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰",
                    "discount_type": "percentage",
                    "discount_value": 20.0,
                    "related_service_id": services[0].id,
                    "start_date": now,
                    "end_date": now + timedelta(days=30)
                },
                {
                    "title": "Ø¹Ø±Ø¶ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø³Ù†Ø§Ù†",
                    "description": "Ø®ØµÙ… 50 Ø±ÙŠØ§Ù„ Ø¹Ù„Ù‰ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø³Ù†Ø§Ù†",
                    "discount_type": "fixed",
                    "discount_value": 50.0,
                    "related_service_id": services[2].id if len(services) > 2 else services[0].id,
                    "start_date": now,
                    "end_date": now + timedelta(days=15)
                }
            ]
        
        offers = []
        for offer_data in offers_data:
            offer = Offer(
                id=uuid.uuid4(),
                title=offer_data["title"],
                description=offer_data["description"],
                discount_type=offer_data["discount_type"],
                discount_value=offer_data["discount_value"],
                related_service_id=offer_data["related_service_id"],
                start_date=offer_data["start_date"],
                end_date=offer_data["end_date"],
                is_active=True,
                created_at=now,
                updated_at=now
            )
            db.add(offer)
            offers.append(offer)
        
        db.commit()
        for offer in offers:
            db.refresh(offer)
        counts["offers"] = len(offers)
        details["offers"] = [o.title for o in offers]
        logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {len(offers)} Ø¹Ø±Ø¶")
        
        # 5. Ø¥Ø¶Ø§ÙØ© FAQs Ù„Ø¹ÙŠØ§Ø¯Ø§Øª Ø¹Ø§Ø¯Ù„ ÙƒÙŠØ±
        faqs_data = [
            {
                "question": "ÙˆØ´ Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø¹Ù…Ù„ØŸ",
                "answer": "Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø¹Ù…Ù„ Ù…Ù† 9 ØµØ¨Ø§Ø­Ø§Ù‹ Ø¥Ù„Ù‰ 9 Ù…Ø³Ø§Ø¡Ù‹ Ù…Ù† Ø§Ù„Ø£Ø­Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ø®Ù…ÙŠØ³ØŒ ÙˆÙ…Ù† 2 Ù…Ø³Ø§Ø¡Ù‹ Ø¥Ù„Ù‰ 10 Ù…Ø³Ø§Ø¡Ù‹ ÙŠÙˆÙ… Ø§Ù„Ø¬Ù…Ø¹Ø©. ÙŠÙˆÙ… Ø§Ù„Ø³Ø¨Øª Ù…Ù† 9 ØµØ¨Ø§Ø­Ø§Ù‹ Ø¥Ù„Ù‰ 9 Ù…Ø³Ø§Ø¡Ù‹",
                "tags": ["Ø³Ø§Ø¹Ø§Øª", "Ø¹Ù…Ù„", "ÙˆÙ‚Øª"]
            },
            {
                "question": "ÙˆÙŠÙ† Ù…ÙˆÙ‚Ø¹ Ø¹ÙŠØ§Ø¯Ø§Øª Ø¹Ø§Ø¯Ù„ ÙƒÙŠØ±ØŸ",
                "answer": "Ù„Ø¯ÙŠÙ†Ø§ ÙØ±ÙˆØ¹ ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶ (Ø­ÙŠ Ø§Ù„Ø¹Ù„ÙŠØ§) ÙˆØ¬Ø¯Ø© (Ø­ÙŠ Ø§Ù„Ø²Ù‡Ø±Ø§Ø¡). ÙŠÙ…ÙƒÙ†Ùƒ Ø²ÙŠØ§Ø±Ø© Ø£ÙŠ ÙØ±Ø¹ Ù…Ù† Ø§Ù„ÙØ±ÙˆØ¹ Ø§Ù„Ù…ØªØ§Ø­Ø©",
                "tags": ["Ù…ÙˆÙ‚Ø¹", "Ø¹Ù†ÙˆØ§Ù†", "ÙØ±ÙˆØ¹"]
            },
            {
                "question": "ÙˆØ´ Ù‡ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©ØŸ",
                "answer": "Ù†Ù‚Ø¯Ù… Ø®Ø¯Ù…Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© ØªØ´Ù…Ù„: Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ø·Ø¨ÙŠØ© Ø¹Ø§Ù…Ø©ØŒ Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ø·Ø¨ Ø§Ù„Ø£Ø·ÙØ§Ù„ØŒ ÙØ­ÙˆØµØ§Øª Ø¯ÙˆØ±ÙŠØ© Ø´Ø§Ù…Ù„Ø©ØŒ Ù…ØªØ§Ø¨Ø¹Ø© Ø­Ø§Ù„Ø§Øª Ù…Ø²Ù…Ù†Ø©ØŒ ÙØ­ÙˆØµØ§Øª Ø§Ù„ØªÙˆØ¸ÙŠÙØŒ ÙˆØ§Ù„ØªØ·Ø¹ÙŠÙ…Ø§Øª",
                "tags": ["Ø®Ø¯Ù…Ø§Øª", "Ø¹Ù„Ø§Ø¬", "Ø§Ø³ØªØ´Ø§Ø±Ø©"]
            },
            {
                "question": "ÙƒÙŠÙ Ø£Ø­Ø¬Ø² Ù…ÙˆØ¹Ø¯ØŸ",
                "answer": "ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø­Ø¬Ø² Ù…Ù† Ø®Ù„Ø§Ù„ ÙˆØ§ØªØ³Ø§Ø¨ØŒ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØŒ Ø£Ùˆ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù†Ø§ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ØªØ§Ø­Ø©",
                "tags": ["Ø­Ø¬Ø²", "Ù…ÙˆØ¹Ø¯", "Ø·Ø±ÙŠÙ‚Ø©"]
            },
            {
                "question": "ÙˆØ´ Ø§Ù„ØªØ®ØµØµØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©ØŸ",
                "answer": "Ù†Ù‚Ø¯Ù… Ø®Ø¯Ù…Ø§Øª ÙÙŠ: Ø·Ø¨ Ø§Ù„Ø¹Ø§Ø¦Ù„Ø©ØŒ Ø·Ø¨ Ø§Ù„Ø£Ø·ÙØ§Ù„ØŒ Ø·Ø¨ Ø§Ù„Ø¨Ø§Ø·Ù†Ø©ØŒ ÙˆØ§Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„ØµØ­ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø©",
                "tags": ["ØªØ®ØµØµ", "Ø£Ø·Ø¨Ø§Ø¡", "Ø®Ø¯Ù…Ø§Øª"]
            }
        ]
        
        # 6. Ø¥Ø¶Ø§ÙØ© Ù…ÙˆØ¸ÙÙŠÙ†
        employees_data = [
            {
                "full_name": "Ø³Ø§Ø±Ø© Ø£Ø­Ù…Ø¯",
                "position": "receptionist",
                "phone_number": "0501111111",
                "email": "sara@adelecare.com",
                "branch_id": branches[0].id if branches else None,
                "hire_date": date(2020, 1, 15),
                "salary": 8000.0
            },
            {
                "full_name": "Ø®Ø§Ù„Ø¯ Ù…Ø­Ù…Ø¯",
                "position": "nurse",
                "phone_number": "0502222222",
                "email": "khalid@adelecare.com",
                "branch_id": branches[0].id if branches else None,
                "hire_date": date(2019, 6, 1),
                "salary": 12000.0
            },
            {
                "full_name": "Ù†ÙˆØ±Ø§ Ø¹Ù„ÙŠ",
                "position": "receptionist",
                "phone_number": "0503333333",
                "email": "nora@adelecare.com",
                "branch_id": branches[1].id if len(branches) > 1 else (branches[0].id if branches else None),
                "hire_date": date(2021, 3, 10),
                "salary": 8000.0
            }
        ]
        
        employees = []
        for employee_data in employees_data:
            employee = Employee(
                id=uuid.uuid4(),
                full_name=employee_data["full_name"],
                position=employee_data["position"],
                branch_id=employee_data["branch_id"],
                phone_number=employee_data.get("phone_number"),
                email=employee_data.get("email"),
                hire_date=employee_data.get("hire_date"),
                salary=employee_data.get("salary"),
                is_active=True,
                created_at=now,
                updated_at=now
            )
            db.add(employee)
            employees.append(employee)
        
        db.commit()
        for employee in employees:
            db.refresh(employee)
        counts["employees"] = len(employees)
        details["employees"] = [e.full_name for e in employees]
        logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {len(employees)} Ù…ÙˆØ¸Ù")
        
        faqs = []
        for faq_data in faqs_data:
            faq = FAQ(
                id=uuid.uuid4(),
                question=faq_data["question"],
                answer=faq_data["answer"],
                tags=faq_data["tags"],
                is_active=True,
                created_at=now,
                updated_at=now
            )
            db.add(faq)
            faqs.append(faq)
        
        db.commit()
        for faq in faqs:
            db.refresh(faq)
        counts["faqs"] = len(faqs)
        details["faqs"] = [f.question for f in faqs]
        logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {len(faqs)} FAQ")
        
        # 7. Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù„Ù„Ù…Ø±Ø¶Ù‰ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ - Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
        patients_data = [
            {
                "full_name": "Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…Ø¯ Ø§Ù„Ø¹Ù„ÙŠ",
                "date_of_birth": date(1990, 5, 15),
                "gender": "male",
                "phone_number": "0501234567",
                "email": "ahmed@example.com",
                "address": "Ø§Ù„Ø±ÙŠØ§Ø¶ØŒ Ø­ÙŠ Ø§Ù„Ù†Ø®ÙŠÙ„"
            },
            {
                "full_name": "ÙØ§Ø·Ù…Ø© Ø³Ø¹ÙŠØ¯",
                "date_of_birth": date(1985, 8, 20),
                "gender": "female",
                "phone_number": "0507654321",
                "email": "fatima@example.com",
                "address": "Ø¬Ø¯Ø©ØŒ Ø­ÙŠ Ø§Ù„Ø²Ù‡Ø±Ø§Ø¡"
            }
        ]
        
        patients = []
        for patient_data in patients_data:
            patient = Patient(
                id=uuid.uuid4(),
                full_name=patient_data["full_name"],
                date_of_birth=patient_data.get("date_of_birth"),
                gender=patient_data.get("gender"),
                phone_number=patient_data["phone_number"],
                email=patient_data.get("email"),
                address=patient_data.get("address"),
                is_active=True,
                created_at=now,
                updated_at=now
            )
            db.add(patient)
            patients.append(patient)
        
        db.commit()
        for patient in patients:
            db.refresh(patient)
        counts["patients"] = len(patients)
        details["patients"] = [p.full_name for p in patients]
        logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {len(patients)} Ù…Ø±ÙŠØ¶")
        
        total_added = sum(counts.values())
        logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­ - Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {total_added} Ø³Ø¬Ù„")
        
        return AddSampleDataResponse(
            success=True,
            message=f"ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­ - ØªÙ… Ø¥Ø¶Ø§ÙØ© {total_added} Ø³Ø¬Ù„",
            details={
                "counts": counts,
                "items": details
            }
        )
        
    except Exception as e:
        db.rollback()
        error_msg = str(e)
        logger.error(f"âŒ ÙØ´Ù„ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©: {error_msg}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©: {error_msg[:200]}"
        )


@router.post("/add-north-branch-data", response_model=AddSampleDataResponse)
async def add_north_branch_data(
    db: Session = Depends(get_db),
    api_key: str = Depends(verify_api_key)
):
    """
    Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª ÙØ±Ø¹ Ø§Ù„Ø´Ù…Ø§Ù„ - Ø­ÙŠ Ø§Ù„Ø­Ø²Ù…
    Ù…Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø±ÙÙ‚: ÙØ±Ø¹ Ø§Ù„Ø´Ù…Ø§Ù„ Ø­ÙŠ Ø§Ù„Ø­Ø²Ù… Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø¹Ù…Ù„ Ù…Ù† Ù¨Øµ Ø­ØªÙ‰ Ù¡Øµ ÙˆØ§Ù„Ø¬Ù…Ø¹Ø© Ù…Ù† Ù¡Ù… Ù¡Øµ
    """
    logger.info("Ø¨Ø¯Ø¡ Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª ÙØ±Ø¹ Ø§Ù„Ø´Ù…Ø§Ù„ - Ø­ÙŠ Ø§Ù„Ø­Ø²Ù…...")
    
    try:
        from app.db.models import Branch, Doctor, Service
        from datetime import datetime
        import uuid
        
        details = {}
        counts = {}
        now = datetime.now()
        
        # 1. Ø¥Ø¶Ø§ÙØ© ÙØ±Ø¹ Ø§Ù„Ø´Ù…Ø§Ù„ - Ø­ÙŠ Ø§Ù„Ø­Ø²Ù…
        # Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø¹Ù…Ù„: Ù…Ù† 8 ØµØ¨Ø§Ø­Ø§Ù‹ Ø­ØªÙ‰ 1 ØµØ¨Ø§Ø­Ø§Ù‹ (Ø§Ù„Ù„ÙŠÙ„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©)
        # Ø§Ù„Ø¬Ù…Ø¹Ø©: Ù…Ù† 1 Ø¸Ù‡Ø±Ø§Ù‹ Ø­ØªÙ‰ 1 ØµØ¨Ø§Ø­Ø§Ù‹
        branch_data = {
            "name": "ÙØ±Ø¹ Ø§Ù„Ø´Ù…Ø§Ù„ - Ø­ÙŠ Ø§Ù„Ø­Ø²Ù…",
            "city": "Ø§Ù„Ø±ÙŠØ§Ø¶",
            "address": "Ø­ÙŠ Ø§Ù„Ø­Ø²Ù…",
            "phone": "0112345679",
            "location_url": "https://maps.google.com/?q=24.7136,46.6753",
            "working_hours": {
                "sunday": {"from": "08:00", "to": "01:00"},
                "monday": {"from": "08:00", "to": "01:00"},
                "tuesday": {"from": "08:00", "to": "01:00"},
                "wednesday": {"from": "08:00", "to": "01:00"},
                "thursday": {"from": "08:00", "to": "01:00"},
                "friday": {"from": "13:00", "to": "01:00"},
                "saturday": {"from": "08:00", "to": "01:00"}
            }
        }
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„ÙØ±Ø¹
        existing_branch = db.query(Branch).filter(Branch.name == branch_data["name"]).first()
        if existing_branch:
            branch = existing_branch
            logger.info(f"âœ… Ø§Ù„ÙØ±Ø¹ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„: {branch.name}")
        else:
            branch = Branch(
                id=uuid.uuid4(),
                name=branch_data["name"],
                city=branch_data["city"],
                address=branch_data["address"],
                phone=branch_data["phone"],
                location_url=branch_data["location_url"],
                working_hours=branch_data["working_hours"],
                is_active=True,
                created_at=now,
                updated_at=now
            )
            db.add(branch)
            db.commit()
            db.refresh(branch)
            logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© ÙØ±Ø¹: {branch.name}")
        
        counts["branches"] = 1
        details["branch"] = branch.name
        
        # 2. Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
        doctors_data = [
            # Ø§Ù„Ø·Ø¨ Ø§Ù„Ø¹Ø§Ù… (4 Ø£Ø·Ø¨Ø§Ø¡)
            {"name": "Ø¯. Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…Ø¯ Ø§Ù„Ø¹Ù„ÙŠ", "specialty": "Ø§Ù„Ø·Ø¨ Ø§Ù„Ø¹Ø§Ù…", "count": 1},
            {"name": "Ø¯. ÙØ§Ø·Ù…Ø© Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡ Ø§Ù„Ø³Ø§Ù„Ù…", "specialty": "Ø§Ù„Ø·Ø¨ Ø§Ù„Ø¹Ø§Ù…", "count": 1},
            {"name": "Ø¯. Ø®Ø§Ù„Ø¯ Ø³Ø¹Ø¯ Ø§Ù„Ø¯ÙˆØ³Ø±ÙŠ", "specialty": "Ø§Ù„Ø·Ø¨ Ø§Ù„Ø¹Ø§Ù…", "count": 1},
            {"name": "Ø¯. Ù†ÙˆØ±Ø§ Ø­Ø³Ù† Ø§Ù„Ù‚Ø­Ø·Ø§Ù†ÙŠ", "specialty": "Ø§Ù„Ø·Ø¨ Ø§Ù„Ø¹Ø§Ù…", "count": 1},
            # Ø§Ù„Ø¨Ø§Ø·Ù†Ø© (1)
            {"name": "Ø¯. Ù…Ø­Ù…Ø¯ Ø¹Ù„ÙŠ Ø§Ù„Ø´Ù…Ø±ÙŠ", "specialty": "Ø§Ù„Ø¨Ø§Ø·Ù†Ø©", "count": 1},
            # Ø§Ø·ÙØ§Ù„ (1)
            {"name": "Ø¯. Ø³Ø§Ø±Ø© Ø£Ø­Ù…Ø¯ Ø§Ù„Ø²Ù‡Ø±Ø§Ù†ÙŠ", "specialty": "Ø§Ø·ÙØ§Ù„", "count": 1},
            # Ø§Ø³Ù†Ø§Ù† (9 Ø£Ø·Ø¨Ø§Ø¡)
            {"name": "Ø¯. Ø¹Ø¨Ø¯Ø§Ù„Ø±Ø­Ù…Ù† ÙÙ‡Ø¯ Ø§Ù„Ù…Ø·ÙŠØ±ÙŠ", "specialty": "Ø§Ø³Ù†Ø§Ù†", "count": 1},
            {"name": "Ø¯. Ù„ÙŠÙ„Ù‰ Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø§Ù„Ø¹ØªÙŠØ¨ÙŠ", "specialty": "Ø§Ø³Ù†Ø§Ù†", "count": 1},
            {"name": "Ø¯. ÙŠÙˆØ³Ù ØµØ§Ù„Ø­ Ø§Ù„Ø­Ø±Ø¨ÙŠ", "specialty": "Ø§Ø³Ù†Ø§Ù†", "count": 1},
            {"name": "Ø¯. Ù…Ù†Ù‰ Ø®Ø§Ù„Ø¯ Ø§Ù„Ø¯ÙˆØ³Ø±ÙŠ", "specialty": "Ø§Ø³Ù†Ø§Ù†", "count": 1},
            {"name": "Ø¯. Ø¨Ù†Ø¯Ø± Ù†Ø§ØµØ± Ø§Ù„Ù‚Ø­Ø·Ø§Ù†ÙŠ", "specialty": "Ø§Ø³Ù†Ø§Ù†", "count": 1},
            {"name": "Ø¯. Ø±ÙŠÙ… Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡ Ø§Ù„Ø³Ø¨ÙŠØ¹ÙŠ", "specialty": "Ø§Ø³Ù†Ø§Ù†", "count": 1},
            {"name": "Ø¯. ØªØ±ÙƒÙŠ ÙÙŠØµÙ„ Ø§Ù„Ø¹Ù„ÙŠ", "specialty": "Ø§Ø³Ù†Ø§Ù†", "count": 1},
            {"name": "Ø¯. Ù‡Ù†Ø§Ø¡ Ù…Ø­Ù…Ø¯ Ø§Ù„Ø´Ù…Ø±ÙŠ", "specialty": "Ø§Ø³Ù†Ø§Ù†", "count": 1},
            {"name": "Ø¯. Ù…Ø§Ø¬Ø¯ Ø³Ø¹Ø¯ Ø§Ù„Ù…Ø·ÙŠØ±ÙŠ", "specialty": "Ø§Ø³Ù†Ø§Ù†", "count": 1},
            # Ù†Ø³Ø§Ø¡ ÙˆÙˆÙ„Ø§Ø¯Ø© (2)
            {"name": "Ø¯. Ø¹Ø¨ÙŠØ± ÙÙ‡Ø¯ Ø§Ù„Ø²Ù‡Ø±Ø§Ù†ÙŠ", "specialty": "Ù†Ø³Ø§Ø¡ ÙˆÙˆÙ„Ø§Ø¯Ø©", "count": 1},
            {"name": "Ø¯. Ù†ÙˆØ±Ø© ØµØ§Ù„Ø­ Ø§Ù„Ø¹ØªÙŠØ¨ÙŠ", "specialty": "Ù†Ø³Ø§Ø¡ ÙˆÙˆÙ„Ø§Ø¯Ø©", "count": 1},
            # Ø¬Ù„Ø¯ÙŠØ© (2)
            {"name": "Ø¯. ÙˆÙ„ÙŠØ¯ Ø®Ø§Ù„Ø¯ Ø§Ù„Ø­Ø±Ø¨ÙŠ", "specialty": "Ø¬Ù„Ø¯ÙŠØ©", "count": 1},
            {"name": "Ø¯. Ø±ÙŠÙ… Ù†Ø§ØµØ± Ø§Ù„Ø¯ÙˆØ³Ø±ÙŠ", "specialty": "Ø¬Ù„Ø¯ÙŠØ©", "count": 1},
        ]
        
        doctors = []
        for doctor_data in doctors_data:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø·Ø¨ÙŠØ¨
            existing_doctor = db.query(Doctor).filter(
                Doctor.name == doctor_data["name"],
                Doctor.branch_id == branch.id
            ).first()
            
            if existing_doctor:
                doctors.append(existing_doctor)
                logger.info(f"â„¹ï¸  Ø§Ù„Ø·Ø¨ÙŠØ¨ Ù…ÙˆØ¬ÙˆØ¯: {doctor_data['name']}")
            else:
                doctor = Doctor(
                    id=uuid.uuid4(),
                    name=doctor_data["name"],
                    specialty=doctor_data["specialty"],
                    branch_id=branch.id,
                    license_number=f"LIC-{uuid.uuid4().hex[:8].upper()}",
                    working_hours=branch_data["working_hours"],  # Ù†ÙØ³ Ø³Ø§Ø¹Ø§Øª Ø§Ù„ÙØ±Ø¹
                    is_active=True,
                    created_at=now,
                    updated_at=now
                )
                db.add(doctor)
                doctors.append(doctor)
        
        db.commit()
        for doctor in doctors:
            db.refresh(doctor)
        
        counts["doctors"] = len(doctors)
        details["doctors"] = [d.name for d in doctors]
        logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {len(doctors)} Ø·Ø¨ÙŠØ¨")
        
        # 3. Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
        services_data = [
            {"name": "Ø§Ù„Ø·Ø¨ Ø§Ù„Ø¹Ø§Ù…", "description": "Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ø·Ø¨ÙŠØ© Ø¹Ø§Ù…Ø© ÙˆÙØ­ÙˆØµØ§Øª Ø¯ÙˆØ±ÙŠØ©", "base_price": 150.0},
            {"name": "Ø§Ù„Ø¨Ø§Ø·Ù†Ø©", "description": "Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¨Ø§Ø·Ù†Ø© ÙˆØ§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù‡Ø¶Ù…ÙŠ", "base_price": 200.0},
            {"name": "Ø·Ø¨ Ø§Ù„Ø£Ø·ÙØ§Ù„", "description": "Ø§Ø³ØªØ´Ø§Ø±Ø§Øª ÙˆØ¹Ù„Ø§Ø¬ Ø§Ù„Ø£Ø·ÙØ§Ù„", "base_price": 180.0},
            {"name": "Ø·Ø¨ Ø§Ù„Ø£Ø³Ù†Ø§Ù†", "description": "Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø£Ø³Ù†Ø§Ù† ÙˆØ§Ù„Ù„Ø«Ø©", "base_price": 250.0},
            {"name": "Ù†Ø³Ø§Ø¡ ÙˆÙˆÙ„Ø§Ø¯Ø©", "description": "Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ù†Ø³Ø§Ø¦ÙŠØ© ÙˆÙ…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ø­Ù…Ù„", "base_price": 300.0},
            {"name": "Ø§Ù„Ø¬Ù„Ø¯ÙŠØ©", "description": "Ø¹Ù„Ø§Ø¬ Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù„Ø¯ ÙˆØ§Ù„Ø¬Ù…Ø§Ù„", "base_price": 200.0},
            {"name": "Ø§Ù„Ù…Ø®ØªØ¨Ø±", "description": "ØªØ­Ø§Ù„ÙŠÙ„ Ø·Ø¨ÙŠØ© Ø´Ø§Ù…Ù„Ø©", "base_price": 100.0},
            {"name": "Ø§Ù„Ø£Ø´Ø¹Ø©", "description": "ÙØ­ÙˆØµØ§Øª Ø§Ù„Ø£Ø´Ø¹Ø© Ø§Ù„ØªØ´Ø®ÙŠØµÙŠØ©", "base_price": 150.0},
            {"name": "Ø§Ù„ØªØ´Ù‚ÙŠØ±", "description": "Ø®Ø¯Ù…Ø§Øª Ø§Ù„ØªØ´Ù‚ÙŠØ± ÙˆØ§Ù„ØªØ¬Ù…ÙŠÙ„", "base_price": 120.0},
        ]
        
        services = []
        for service_data in services_data:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø®Ø¯Ù…Ø©
            existing_service = db.query(Service).filter(Service.name == service_data["name"]).first()
            
            if existing_service:
                services.append(existing_service)
                logger.info(f"â„¹ï¸  Ø§Ù„Ø®Ø¯Ù…Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©: {service_data['name']}")
            else:
                service = Service(
                    id=uuid.uuid4(),
                    name=service_data["name"],
                    description=service_data["description"],
                    base_price=service_data["base_price"],
                    is_active=True,
                    created_at=now,
                    updated_at=now
                )
                db.add(service)
                services.append(service)
        
        db.commit()
        for service in services:
            db.refresh(service)
        
        counts["services"] = len(services)
        details["services"] = [s.name for s in services]
        logger.info(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {len(services)} Ø®Ø¯Ù…Ø©")
        
        # Ù…Ù„Ø®Øµ
        summary = f"""
âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª ÙØ±Ø¹ Ø§Ù„Ø´Ù…Ø§Ù„ - Ø­ÙŠ Ø§Ù„Ø­Ø²Ù… Ø¨Ù†Ø¬Ø§Ø­!

ğŸ“Š Ø§Ù„Ù…Ù„Ø®Øµ:
- Ø§Ù„ÙØ±ÙˆØ¹: {counts.get('branches', 0)}
- Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡: {counts.get('doctors', 0)}
- Ø§Ù„Ø®Ø¯Ù…Ø§Øª: {counts.get('services', 0)}

ğŸ¥ Ø§Ù„ÙØ±Ø¹: {branch.name}
ğŸ“ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {branch.address}
â° Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø¹Ù…Ù„: Ù…Ù† 8 ØµØ¨Ø§Ø­Ø§Ù‹ Ø­ØªÙ‰ 1 ØµØ¨Ø§Ø­Ø§Ù‹ (Ø§Ù„Ø¬Ù…Ø¹Ø© Ù…Ù† 1 Ø¸Ù‡Ø±Ø§Ù‹)
        """
        
        return AddSampleDataResponse(
            success=True,
            message=summary.strip(),
            details={
                "counts": counts,
                "branch": branch.name,
                "doctors_count": len(doctors),
                "services_count": len(services),
                "working_hours": branch.working_hours
            }
        )
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"âŒ ÙØ´Ù„ Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª ÙØ±Ø¹ Ø§Ù„Ø´Ù…Ø§Ù„: {error_msg}", exc_info=True)
        
        # ØªØ­Ø³ÙŠÙ† Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©
        if "does not exist" in error_msg.lower() or "relation" in error_msg.lower():
            raise HTTPException(
                status_code=400,
                detail=f"âŒ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!\n\nÙŠØ¬Ø¨ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹:\n1. Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± 'ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª' ÙÙŠ ØµÙØ­Ø© test-chat\n2. Ø«Ù… Ø­Ø§ÙˆÙ„ Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª ÙØ±Ø¹ Ø§Ù„Ø´Ù…Ø§Ù„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰\n\nØ§Ù„Ø®Ø·Ø£ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ: {error_msg[:150]}"
            )
        
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª ÙØ±Ø¹ Ø§Ù„Ø´Ù…Ø§Ù„: {error_msg[:200]}"
        )

